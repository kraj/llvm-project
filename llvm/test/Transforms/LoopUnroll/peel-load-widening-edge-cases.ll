; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --version 5
; RUN: opt -p loop-unroll -unroll-full-max-count=0 -S %s | FileCheck %s

; Test edge cases where loop peeling for consecutive load widening should NOT apply.
; These ensure the optimization correctly avoids unsafe scenarios.

; Test case 1: Intervening store should prevent peeling
define void @test_intervening_store(ptr %src, ptr %dst, i32 %n) {
; CHECK-LABEL: define void @test_intervening_store(
; CHECK-SAME: ptr [[SRC:%.*]], ptr [[DST:%.*]], i32 [[N:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*]]:
; CHECK-NEXT:    br label %[[LOOP:.*]]
; CHECK:       [[LOOP]]:
; CHECK-NEXT:    [[TMP3:%.*]] = phi i32 [ 0, %[[ENTRY]] ], [ [[I_NEXT:%.*]], %[[LOOP]] ]
; CHECK-NEXT:    [[TMP4:%.*]] = phi ptr [ [[SRC]], %[[ENTRY]] ], [ [[P_NEXT_PEEL:%.*]], %[[LOOP]] ]
; CHECK-NEXT:    [[P1_PEEL:%.*]] = getelementptr inbounds i8, ptr [[TMP4]], i64 1
; CHECK-NEXT:    [[P2_PEEL:%.*]] = getelementptr inbounds i8, ptr [[TMP4]], i64 2
; CHECK-NEXT:    [[A_PEEL:%.*]] = load i8, ptr [[TMP4]], align 4
; CHECK-NEXT:    store i8 42, ptr [[P1_PEEL]], align 1
; CHECK-NEXT:    [[B_PEEL:%.*]] = load i8, ptr [[P1_PEEL]], align 1
; CHECK-NEXT:    [[C_PEEL:%.*]] = load i8, ptr [[P2_PEEL]], align 1
; CHECK-NEXT:    [[SUM1_PEEL:%.*]] = add i8 [[A_PEEL]], [[B_PEEL]]
; CHECK-NEXT:    [[SUM2_PEEL:%.*]] = add i8 [[SUM1_PEEL]], [[C_PEEL]]
; CHECK-NEXT:    [[DST_I_PEEL:%.*]] = getelementptr inbounds i8, ptr [[DST]], i32 [[TMP3]]
; CHECK-NEXT:    store i8 [[SUM2_PEEL]], ptr [[DST_I_PEEL]], align 1
; CHECK-NEXT:    [[P_NEXT_PEEL]] = getelementptr inbounds i8, ptr [[TMP4]], i64 3
; CHECK-NEXT:    [[I_NEXT]] = add i32 [[TMP3]], 1
; CHECK-NEXT:    [[COND:%.*]] = icmp ne i32 [[I_NEXT]], [[N]]
; CHECK-NEXT:    br i1 [[COND]], label %[[LOOP]], label %[[EXIT:.*]]
; CHECK:       [[EXIT]]:
; CHECK-NEXT:    ret void
;
entry:
  br label %loop

loop:
  %i = phi i32 [ 0, %entry ], [ %i.next, %loop ]
  %p = phi ptr [ %src, %entry ], [ %p.next, %loop ]

  %p1 = getelementptr inbounds i8, ptr %p, i64 1
  %p2 = getelementptr inbounds i8, ptr %p, i64 2

  %a = load i8, ptr %p, align 4
  store i8 42, ptr %p1, align 1  ; Intervening store prevents optimization
  %b = load i8, ptr %p1, align 1
  %c = load i8, ptr %p2, align 1

  %sum1 = add i8 %a, %b
  %sum2 = add i8 %sum1, %c
  %dst.i = getelementptr inbounds i8, ptr %dst, i32 %i
  store i8 %sum2, ptr %dst.i, align 1

  %p.next = getelementptr inbounds i8, ptr %p, i64 3
  %i.next = add i32 %i, 1
  %cond = icmp ne i32 %i.next, %n
  br i1 %cond, label %loop, label %exit

exit:
  ret void
}

; Test case 2: Non-consecutive loads should not trigger peeling
define void @test_non_consecutive_loads(ptr %src, ptr %dst, i32 %n) {
; CHECK-LABEL: define void @test_non_consecutive_loads(
; CHECK-SAME: ptr [[SRC:%.*]], ptr [[DST:%.*]], i32 [[N:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*]]:
; CHECK-NEXT:    br label %[[LOOP:.*]]
; CHECK:       [[LOOP]]:
; CHECK-NEXT:    [[I:%.*]] = phi i32 [ 0, %[[ENTRY]] ], [ [[I_NEXT:%.*]], %[[LOOP]] ]
; CHECK-NEXT:    [[P:%.*]] = phi ptr [ [[SRC]], %[[ENTRY]] ], [ [[P_NEXT:%.*]], %[[LOOP]] ]
; CHECK-NEXT:    [[P1:%.*]] = getelementptr inbounds i8, ptr [[P]], i64 2
; CHECK-NEXT:    [[P2:%.*]] = getelementptr inbounds i8, ptr [[P]], i64 5
; CHECK-NEXT:    [[A:%.*]] = load i8, ptr [[P]], align 1
; CHECK-NEXT:    [[B:%.*]] = load i8, ptr [[P1]], align 1
; CHECK-NEXT:    [[C:%.*]] = load i8, ptr [[P2]], align 1
; CHECK-NEXT:    [[SUM1:%.*]] = add i8 [[A]], [[B]]
; CHECK-NEXT:    [[SUM2:%.*]] = add i8 [[SUM1]], [[C]]
; CHECK-NEXT:    [[DST_I:%.*]] = getelementptr inbounds i8, ptr [[DST]], i32 [[I]]
; CHECK-NEXT:    store i8 [[SUM2]], ptr [[DST_I]], align 1
; CHECK-NEXT:    [[P_NEXT]] = getelementptr inbounds i8, ptr [[P]], i64 6
; CHECK-NEXT:    [[I_NEXT]] = add i32 [[I]], 1
; CHECK-NEXT:    [[COND:%.*]] = icmp ne i32 [[I_NEXT]], [[N]]
; CHECK-NEXT:    br i1 [[COND]], label %[[LOOP]], label %[[EXIT:.*]]
; CHECK:       [[EXIT]]:
; CHECK-NEXT:    ret void
;
entry:
  br label %loop

loop:
  %i = phi i32 [ 0, %entry ], [ %i.next, %loop ]
  %p = phi ptr [ %src, %entry ], [ %p.next, %loop ]

  %p1 = getelementptr inbounds i8, ptr %p, i64 2  ; Skip offset 1 - non-consecutive
  %p2 = getelementptr inbounds i8, ptr %p, i64 5  ; Skip offset 3,4 - non-consecutive

  %a = load i8, ptr %p, align 1
  %b = load i8, ptr %p1, align 1
  %c = load i8, ptr %p2, align 1

  %sum1 = add i8 %a, %b
  %sum2 = add i8 %sum1, %c
  %dst.i = getelementptr inbounds i8, ptr %dst, i32 %i
  store i8 %sum2, ptr %dst.i, align 1

  %p.next = getelementptr inbounds i8, ptr %p, i64 6
  %i.next = add i32 %i, 1
  %cond = icmp ne i32 %i.next, %n
  br i1 %cond, label %loop, label %exit

exit:
  ret void
}

; Test case 3: Power-of-2 load groups should not be peeled (already optimal)
define void @test_power_of_2_no_peel(ptr %src, ptr %dst, i32 %n) {
; CHECK-LABEL: define void @test_power_of_2_no_peel(
; CHECK-SAME: ptr [[SRC:%.*]], ptr [[DST:%.*]], i32 [[N:%.*]]) {
; CHECK-NEXT:  [[ENTRY:.*]]:
; CHECK-NEXT:    br label %[[LOOP:.*]]
; CHECK:       [[LOOP]]:
; CHECK-NEXT:    [[I:%.*]] = phi i32 [ 0, %[[ENTRY]] ], [ [[I_NEXT:%.*]], %[[LOOP]] ]
; CHECK-NEXT:    [[P:%.*]] = phi ptr [ [[SRC]], %[[ENTRY]] ], [ [[P_NEXT:%.*]], %[[LOOP]] ]
; CHECK-NEXT:    [[P1:%.*]] = getelementptr inbounds i8, ptr [[P]], i64 1
; CHECK-NEXT:    [[P2:%.*]] = getelementptr inbounds i8, ptr [[P]], i64 2
; CHECK-NEXT:    [[P3:%.*]] = getelementptr inbounds i8, ptr [[P]], i64 3
; CHECK-NEXT:    [[A:%.*]] = load i8, ptr [[P]], align 4
; CHECK-NEXT:    [[B:%.*]] = load i8, ptr [[P1]], align 1
; CHECK-NEXT:    [[C:%.*]] = load i8, ptr [[P2]], align 1
; CHECK-NEXT:    [[D:%.*]] = load i8, ptr [[P3]], align 1
; CHECK-NEXT:    [[SUM1:%.*]] = add i8 [[A]], [[B]]
; CHECK-NEXT:    [[SUM2:%.*]] = add i8 [[SUM1]], [[C]]
; CHECK-NEXT:    [[SUM3:%.*]] = add i8 [[SUM2]], [[D]]
; CHECK-NEXT:    [[DST_I:%.*]] = getelementptr inbounds i8, ptr [[DST]], i32 [[I]]
; CHECK-NEXT:    store i8 [[SUM3]], ptr [[DST_I]], align 1
; CHECK-NEXT:    [[P_NEXT]] = getelementptr inbounds i8, ptr [[P]], i64 4
; CHECK-NEXT:    [[I_NEXT]] = add i32 [[I]], 1
; CHECK-NEXT:    [[COND:%.*]] = icmp ne i32 [[I_NEXT]], [[N]]
; CHECK-NEXT:    br i1 [[COND]], label %[[LOOP]], label %[[EXIT:.*]]
; CHECK:       [[EXIT]]:
; CHECK-NEXT:    ret void
;
entry:
  br label %loop

loop:
  %i = phi i32 [ 0, %entry ], [ %i.next, %loop ]
  %p = phi ptr [ %src, %entry ], [ %p.next, %loop ]

  %p1 = getelementptr inbounds i8, ptr %p, i64 1
  %p2 = getelementptr inbounds i8, ptr %p, i64 2
  %p3 = getelementptr inbounds i8, ptr %p, i64 3

  %a = load i8, ptr %p, align 4
  %b = load i8, ptr %p1, align 1
  %c = load i8, ptr %p2, align 1
  %d = load i8, ptr %p3, align 1

  %sum1 = add i8 %a, %b
  %sum2 = add i8 %sum1, %c
  %sum3 = add i8 %sum2, %d
  %dst.i = getelementptr inbounds i8, ptr %dst, i32 %i
  store i8 %sum3, ptr %dst.i, align 1

  %p.next = getelementptr inbounds i8, ptr %p, i64 4
  %i.next = add i32 %i, 1
  %cond = icmp ne i32 %i.next, %n
  br i1 %cond, label %loop, label %exit

exit:
  ret void
}
